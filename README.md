# [毕业设计] 基于图神经网络的多Agent充电路径规划

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-1.10%2B-orange)

## 📌 项目背景和意义

物联网（Internet of Things, IoT）作为信息技术与通信技术领域中的一项重要技术，近年来取得了显著的发展。物联网是指通过互联网连接、感知和通信技术，使各种设备和系统能够相互交互、收集数据，并实现智能化、自动化的网络。这些设备可以是各种各样的物理对象，如传感器、执行器、嵌入式设备等。随着科技的进步，物联网在各行各业得到广泛应用，为人们的生活和工业生产提供了更加便捷和智能的解决方案。

随着物联网技术的发展，其规模逐渐扩大，尤其在工业中，物联网系统中的设备数量呈爆炸式增长。设备数量的增加使得我们能够更精细地了解和控制周围环境，但按照传统方法维护这些静态传感设备变得越来越昂贵。**如何为这些静态设备提供低成本的、持续的能源供应成为一个日益突出且重要的问题。**

得益于人工智能的不断发展成熟，**部署移动Agent给物联网设备充电并使用人工智能算法进行路径规划**已逐渐变得可行。该问题可以形式化为完全带权图。单个机器人的路径规划可以被形式化为旅行商问题（Travelling Salesman Problem, TSP），即选择一条路线经过所有节点一次，并使总路线长度最小。对于解决多旅行商问题（Multiple Trravelling Salesmen Problem, mTSP）可以运用分治的思想：对于有n个机器人的mTSP问题，将图划分为n个子图，每个子图便退化成了单机器人的TSP问题。

然而，目前的研究仍存在一些不足之处。首先，绝大部分TSP的研究均是静态TSP问题，而对本问题来说，**机器人到达某设备处需要停顿一段时间对设备进行充电，该时间是不定的，且往往不可忽略：当前设备电量越多，充电时间越短；反之，充电时间越长**。因此该问题是一个具有动态需求的TSP问题。其次，对考虑动态需求的TSP问题的大部分研究只考虑了单个机器人的TSP问题，对具有动态需求的多机器人的TSP问题没有一个成熟的算法。另外，对一般的TSP问题的研究很难考虑到机器人可能需要多次往返基站节点进行充电的情况。因此，现有研究在该问题上仍有很大提升完善的空间。

综上所述，本项目旨在深入研究物联网环境下的机器人路径规划问题，特别是在考虑了动态需求和多机器人情境下，提供一种高效且实用的移动机器人路径规划方案。

> **毕设关键词**：强化学习、多头注意力机制、图神经网络、旅行商问题

## 🚀 模型结构
本项目基于论文《A learning approach for multi-agent travelling problem with dynamic service requirement in mobile IoT》提出的GAPN网络架构进行扩展。原论文针对单Agent场景下的动态服务需求路径规划问题提出了解决方案，本项目在此基础上采用了**两阶段推理框架**来解决多Agent场景：
1. **图划分阶段**  
   - 使用自定义网络将服务区域划分为多个子图
   - 每个子图对应一个Agent的专属服务区域
2. **路径规划阶段**  
   - 各子图通过独立的GAPN网络进行路径优化
   - 支持并行计算以提高效率

### 图划分阶段详解
本阶段参考多头注意力机制：在类编码器阶段生成每个Agent专属的注意力头，使得每个Agent关注不同的部分；在类解码器阶段生成节点分配概率。

**类编码器阶段**  
1. 通过图同构网络生成：
   - 节点级嵌入（Node Embeddings）
   - 全图嵌入（Graph Embedding）
2. 将全图嵌入作为Query，节点嵌入作为Key/Value
3. 输出各Agent独特的嵌入表示

**类解码器阶段**  
1. 计算Agent嵌入与节点嵌入的相关性
2. 采用放大双曲正切（Scaled tanh）激活
3. 通过Softmax输出节点分配概率

### 图划分网络训练
**强化学习架构**  
将划分网络任务形式化为单步马尔可夫决策过程（MDP），奖励函数$R = -\max(\mathcal{L}_{\text{GAPN}})$，即第二阶段各子图损失最大值的相反数。


**负载均衡**
使用上述奖励的Policy Gradient算法可自动实现负载均衡，无需显式约束子图节点数。好处有：
 -  允许子图间合理数量差异（提升模型泛化性）
 -   奖励设计天然避免策略退化


**S-Batch REINFORCE算法**
在S-Batch REINFORCE中，优势函数$A_t = R(t) - \frac{1}{s}\sum_{i=1}^s R(t_i)$ ，其中 $s$ 为批次大小，即当前回报减去s批次的期望回报。 使用S-Batch REINFORCE可在不显著增加模型复杂度的前提下降低梯度估计方差。


**Parallel Inference Strategy**
针对以往工作由于子图节点数量不同导致第二阶段推理效率低下，本文创新性地提出了一种并行推理策略Parallel Inference Strategy，通过尾部补全depot节点实现子图对齐，利用掩码机制保证GAPN推理不受补全节点影响。




> Written with [StackEdit](https://stackedit.io/).
